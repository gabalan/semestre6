cours 1 (Lundi 09/01/17):
-------------------------
Notions de compilateur et d'interprete (ou interpreteur).
Présentation de l'UE:
- plan du cours
- deroulement dans le temps
- evaluation
(voir les deux .pdf:
sur http://dept-info.labri.fr/~ges/ENSEIGNEMENT/COMPILATIONL3/cours_td_compi.html
accessibles aussi en 2 clics a partir de ma page d'accueil).

cours 2 (Mardi 10/01/17):
-------------------------

- References bibliographiques (Dragon + Bison-Fex chez O'Reilly)
voir aussi page web.

- Langage IMP (langage source du mini-projet):
 * syntaxe (la grammaire de Goubault-Larrecq "toute crue", page 2)
 [qui s'avere ambigue, mais ils s'en apercevront plus tard]
 * semantique: la semantique operationnelle a petits pas (voir Goubault-Larrecq,
 Figure 2, page 6).
- Un exemple de programme imp (pex4.ip ci-joint)
- sur l'exemple:
 * analyse lexicale
 * analyse syntaxique

cours 3 (Lundi 16/01/17):
-------------------------
- Suite de l'exemple:
 * distinction entre l'"arbre de derivation" et l' "arbre abstrait".
 * passage de l' arbre abstrait au code a 3 adresses
 * du code a 3 adresses au langage Y86.
 (fichier pex4.ys ci-joint)

- Schema general des phases d'un compilateur.

- Deroulement de la semantique operationelle a petits pas sur deux exemples
(un avec seulement des operations arith et des affectations; le second avec un while).

cours 4 (Mardi 17/01/17):
-------------------------
Analyse lexicale.

1- Langages rationnels versus reconnaissables
  * bref rappel
  * algo de Brozowski-Mc-Cluskey de passage d'un automate a une expression reguliere:
   introduit naturellement des "automates a transitions regulieres"
  * definitions regulieres enchassees (mais bien-fondees)
  * extensions des operations regulieres (comme dans sed, bash, etc ...)
  
2- Generateur FLEX d'analyseurs lexicaux.
  * principe: .l --> .c --> a.out
  * les 3 sections (definitions, regles, fonctions )
  * semantique des regles: prefixe le plus long, a egalite de longueur, premier lexeme
  * exemple: l'exo 5 de la feuille de TD 1.

NB1: je n'ai pas parle des contextes droits (indiques par /), de yyless(n), de REJECT,
ni meme des "start conditions" (mais ils ont vu le principe au paragraphe 1:
les "automates a transitions regulieres").
Je suggere qu'on introduise ces notions complementaires au fur et a mesure des
besoins, en TP.

cours 5 (Lundi 23/01/17):
-------------------------
Automates  pile.

1- Les automates:
classification en fonction de la "structure memoire" i.e. l'ensemble de ses valeurs
possibles et les operations autorisees
a memoire finie, a 1 compteur, a p (\geq 2) compteurs, a pile, a arbre, a pile de piles,
a piles d'arbres, etc ...

2- Automates a pile: 
* definition, 
* exemple ($L= \{ u \in \{a,b\}^*\# \mid|u|_a = |u|_b \}$
* notion de determinisme (informel)

3- Theoreme 3: les langages engendres par les grammaires c.f. sont exactement les
langages reconus par des automates a pile.

Grammaires --> automates:
automate d'analyse descendante

N.B.: je laisse a Adrian le soin d'expliquer la reciproque: 
partant d'un automate a pile, comment construire une grammaire c.f.

cours 6 (Lundi 30/01/17):
-------------------------
Termine l'automate d'analyse descendante d'une grammaire c.f. G:
* definition,
* exemple: grammaire S -> aSSb + c
* propriete: la suite des regles utilisees est une derivation gauche dans G

Automate d'analyse ascendante d'une grammaire c.f. G:
* definition,
* exemple: grammaire S -> aSSb + c
* propriete: la suite des regles utilisees est le miroir d'une derivation droite
dans G.

Notion d'analyseur deterministe: pas de conflit decaller-reduire, ni reduire-reduire.
Apercu en avant:
* classes de grammaires ou l'automate d'analyse descendante est deterministe: LL(1)
* classes de grammaires ou l'automate d'analyse ascendante est deterministe:
LR(0), SLR(1), LALR(1), LR(1) .

cours 7 (Lundi 06/02/17):
-------------------------
1- Grammaires LL(1).

Grammaires LL(1) [Left-to-right, top-down, with Look-ahead of length 1].
Idée générale: une classe de grammaires permettant une analyse descendante,
de gauche à droite, déterministe. Une "vue-en-avant" sur un caractère après
le caractère analysé est autorisée.

Notions préliminaires:
pour tout non-terminal v: ensembles Premier (v) et Suivant (v).

Définition:
G est LL(1) ssi, pour tout couple de règles (v,m),(v,m'),
$$Premier(m \cdot Suivant(v)) \cap Premier(m' \cdot Suivant(v))= \emptyset .$$

2- Automate a pile deterministe ${\cal A}$ associé à une grammaire G qui est LL(1).

Lemme 1: Tout calcul de ${\cal A}$ "correspond" à une dérivation gauche de G.

Lemme 2: Toute dérivation gauche de G "correspond" à un calcul acceptant de ${\cal A}$.

Théorème 3: Si G est LL(1), le langage engendré par G (suivi du marqueur $),
est égal au langage reconnu (par pile vide) par ${\cal A}$.

3- Calcul des fonctions Premier et Suivant.

On se ramène à des calculs d'accessibilité dans des graphes finis.

Corollaires:
* On peut décider si une grammaire c.f. G est LL(1)
* On peut construire (lorsque G est LL(1)) l'a.d.p. ${\cal A}$ associé à G.

cours 8 (Lundi 13/02/17):
-------------------------
1- Grammaires LR(0).[Left-to-right, bottom-up, with Look-ahead of length 0].
Idée générale: une classe de grammaires permettant une analyse ascendante,
de gauche à droite, déterministe.

Definitions techniques:
item LR(0), item valide pour un mot w \in ((X \cup V)^*,
prefixe viable.

Proposition 1:
Automate A0 non-deterministe des items valides.
Pour tout mot w\in ((X \cup V)^*, l' ensemble des etats accessibles , par A0,
en lisant w, est exactement l'ensemble des items valides pour w.

Automate D0: c'est le determinise de A0 (par la construction vue avec A. Tanasa).

Proposition 2:
Idem que Prop1, mais pour D0.

Definition 3:
Une grammaire c.f. est LR(0) ssi, aucun etat accessible de l'automate D0
ne contient un "conflit" (decaller-reduire ou reduire-reduire).

(contre-)Exemple: grammaire
sigma -> S
S -> SbS
S -> d

2- Analyseur syntaxique {\cal A} associ'e a une grammaire.
Definition (transitions de reduction, transitions de decallage).

Theoreme 4:
1- {\cal A} reconnait exactement L(G)
2- Si G est LR(0), {\cal A} est deterministe.

cours 9 (Lundi 27/02/17):
-------------------------
Un exemple de grammaire (stylisation des instructions while):

H: C -> C s C | b C e | w C | i
ou les non-terminaux sont C
et les terminaux sont s,b,e,w,i
[abbreviations de Sequence, Begin, End, While e Do, Instruction].
Remarquer que cette grammaire est ambiguee;
par exemple "w i s i" a deux arbres de derivation
Intuitivement "while e  do  ins1 ; ins2"
peut etre analyse comme:
 "(while e  do  ins1) ; ins2"
 ou bien comme:
 "while e  do  (ins1 ; ins2)"

On propose la grammaire suivante G :
C -> A s C | A
A -> w A | b C e | i

ou les non-terminaux sont C, A
et les terminaux sont s,b,e,w,i

Question 1: cette grammaire G peut-elle etre analysee
par un analyseur deterministe de gauche a droite ?

Question 2: Cette grammaire G engendre-t-elle le meme langage que H ?

Solution de la Q1:
-----------------
- on calcule l'automate des items LR(0) de G;
on constate que G n'est pas LR(0)
- on remarque que, en tenant compte d'un regard-en-avant de longueur 1, on peut
construire un analyseur LR deterministe.
- on remarque meme que, en fusionnant les ensembles d'items LR(1) qui se projettent
sur un meme ensemble d'items LR(0), l'analyseur demeure deterministe.
[c'est un exemple de grammaire "LALR(1)"]

cours 10 (Lundi 06/03/17):
-------------------------
1- Grammaires attribuées:
* notion d'attributs, de règles de calcul d'attributs
* attributs synthetises
* attributs herites
* grammaire S-attribuee (i.e. dont tous les attributs sont synthetises)
* grammaire L-attribuee (i.e. dont toute regle de calcul d'attribut
a pour arguments, soit des attributs des fils, soit des attributs du pere
et des freres gauches)

2- Calcul des attributs:
* graphe de dependance (pour un arbre de derivation donne)
* Non-circularite (i.e. non-existence d'un arbre de derivation dont le graphe
de dependance comporte  un circuit)
* algorithmes de calcul des attributs:
  ** cas d'attributs synthetises: calcul dans la pile de l'analyseur LR
  (si la grammaire admet un analyseur LR), sinon parcours ascendant de l'arbre;
  ** cas de L-attributs: calcul par un parcours en profondeur, de gauche a droite
  de l'arbre;
  ** cas general: tri topologique du graphe de dependance; puis calcul
  des attributs en parcourant l'arbre dans l'ordre du tri topologique
  N.B. En reponse a une question d'un etudiant: on calcule ainsi le plus petit
  (au sens de l'ordre "etre moins defini ") vecteur de valeurs des attributs
  satisfaisant les "regles de calcul". Il se peut qu'il existe plusieurs solutions
  (non-minimales).

[Ces deux paragraphes correspondent aux pages 303-314 du Dragon, version pointee par
notre site-web:
http://www.informatik.uni-bremen.de/agbkb/lehre/ccfl/Material/ALSUdragonbook.pdf
]

3- Implantation dans BISON:
* seulement des attributs synthetises, un seul attribut par non-terminal
* syntaxe de BISON: $$, $i,  %union

cours 11 (Lundi 13/03/17):
-------------------------
1- Solution de la question 2 (grammaires et equations en langages).
Lemme 1: L(G,C) \subseteq L(H,C).
Preuve: par reecriture.

Lemme 2: L(H,C) \subseteq L(G,C).
Preuve: par equations et inequations (en utilisant le theoreme de Ginsburg et Rice).

On pose L := L(G,C), L_a := L(G,A).

Par le lemme d'Arden: L = (L_a s)^*L_a
On en deduit successivement:

L s L \subseteq L 
b L e + i \subseteq L
w L_a \subseteq L
w L \subseteq L
L s L + b L e + w L + i \subseteq L

Mais la plus petite solution de cette inequation est L(H,C).
Donc L \subseteq L(H,C)
qed.

2- Grammaires LR(1).
Definitions techniques:
item LR(1), item valide pour un mot w \in ((X \cup V)^*,
prefixe viable.

Proposition 1:
Automate A1 non-deterministe des items valides.
Pour tout mot w \in ((X \cup V)^*, l' ensemble des etats accessibles , par A1,
en lisant w, est exactement l'ensemble des items valides pour w.

Automate D1: c'est le determinise de A1 (par la construction vue avec A. Tanasa).

Proposition 2:
Idem que Prop1, mais pour D1.

Definition 3:
Une grammaire c.f. est LR(1) ssi, aucun etat accessible de l'automate D1
ne contient un "conflit" (decaller-reduire ou reduire-reduire).

3-
Notion d'analyseur LR {\cal A} associ'e a une grammaire:
Ensemble d'etats E, fonctions Action et Successeur
Definition (transitions de reduction, transitions de decallage).

Analyseur LR {\cal A} associe a une grammaire LR(1).

Theoreme 4:
Si G est LR(1), alors {\cal A} reconnait exactement L(G).

Apres 12h 20: reponse a quelques questions sur le mini-projet
* Q: est-ce que le traducteur de IMP vers C3A, doit produire un fichier texte ?
ou bien des objets structures du langage C ?
reponse: des objets structures cela suffit.
Une fonction de visualisation de ces objets est bien sur utile a la mise au point
des differents traducteurs et interpretes.
On peut aussi produire un fichier texte, puis utiliser l'exercice de la feuille
de TD/TP 2 pour le traducteur et l'interprete qui partent du code C3A.

* Q: a quelle heure doit-on rendre le mini-projet ?
reponse: avant le 15/03 a 23h 59' 59''

* Q: et le "grand" projet, on le connaitra quand  ?
reponse: j'essaye de vous le donner la semaine prochaine.

* en apparté a un petit groupe de 2 qui me montre ses bugs ...:
Q: et si on le rend trop tard ?
reponse: il y aura des points en moins a chaque journee de retard.

cours 12 (Lundi 20/03/17):
-------------------------
1- Sémantique à grands pas d'un langage de programmation.

- Syntaxe de IMP par "règles d'inférence" au lieu de règles de réécriture

- Sémantique à grands pas de IMP: "règles d'inf\érence" calquées sur les règles
de syntaxe

- Comment r\éaliser un imterprèteur à partir des règles d'inf\érences ?

Principe:
On part de l'environnement en bas à droite, on remonet aux hypotheses en haut à gauche,
on applique (r\écursivement) l'interpr\éteur pour obtenir les conclusions
en haut à droite, on redescend en bas à droite: c'est le nouvel environnement.

2- Présentation du langage Pseudo_pascal (à interpréter et compiler en projet):

- distribution d'une grammaire (format Bison); elle est ambiguee (donc pas LALR(1),
mais engendre PP
- plan général d'un programme: déclarations de variables globales, déclarations de
fonctions/procédures, corps du programme.
- notion d'environnement global G , tas H , environnement local E

Etats de la machine abstraite ${\cal M}$: triplets (G,H,E)
Transitions de la machine abstraite: définie par des règles d'inférence

On détaille quatre règles d'inférence:
* variable locale
* variable globale
* lecture dans un tableau
* appel de procédure

3- Une difficulté:

Le CREMI n'a pas acheté la machine ${\cal M}$ :-(  Que faire ?
Réponse: on utilise une machine ${\cal M}'$, dont la mémoire est linéaire
(on la voit comme un grand tableau) et qui est incarnée dans une machine du CREMI.
On définit une bisimulation entre les états de ${\cal M}$ et certains états de
${\cal M}'$. On peut ainsi traduire tout interprète de PP sur la machine ${\cal M}$
(celui d\éfini par les règles d'inférence, par exemple) en
un interprète sur la machine ${\cal M}'$: la structure de contrôle est la même,
mais les opérations élémentaires de ${\cal M}$ sont remplacées par des suites
d'opérations de ${\cal M}'$, de facon à respecter la bisimulation entre états.


Information culturelle:
X. Leroy et son équipe d'INRIA ont réalisé un compilateur C, dont la
correction est prouvée: la bisimulation entre la machine abstraite de
depart (munie du programme source) et la machine X86 d'arrivée (munie
du programme traduit) est prouvée formellement, en COQ [projet
COMPCERT, http://compcert.inria.fr/]
